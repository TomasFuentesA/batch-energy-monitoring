version: "3.9"

networks:
  batch-energy-monitoring:
    name: batch-energy-monitoring # Nombre expl√≠cito para la red

volumes:
  data_raw:
    driver: local
  data_clean:
    driver: local

services:
  postgres:
    networks:
      - batch-energy-monitoring
    build: ./db
    restart: always
    container_name: postgres   
    ports:
      - "5432:5432"
    environment:
      - bind-address=0.0.0.0
      - POSTGRESQL_DATABASE=batch_energy_monitoring
      - POSTGRESQL_USERNAME=energyuser
      - POSTGRESQL_PASSWORD=energypass
  spark-master:
    networks:
      - batch-energy-monitoring
    build:
      context: .
      dockerfile: spark_jobs/Dockerfile
    container_name: spark-master
    volumes:
      - ./spark_jobs:/app
      - data_raw:/app/data/raw
      - data_clean:/app/data/clean
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - SPARK_MODE=master
  insert_clean_data:
    networks:
      - batch-energy-monitoring
    build:
      context: .
      dockerfile: scripts/Dockerfile
    container_name: insert_clean_data
    command: ["spark-submit", "--master", "local[*]", "insert_clean_data.py"]
    depends_on:
      - postgres
    volumes:
      - data_clean:/app/data/clean
      - ./scripts:/app
    environment:
      - SPARK_MODE=client
  insert_raw_data:
    networks:
      - batch-energy-monitoring
    build:
      context: .
      dockerfile: scripts/Dockerfile
    container_name: insert_raw_data
    command: ["spark-submit", "--master", "local[*]", "insert_raw_data.py"]
    depends_on:
      - postgres
    volumes:
      - data_raw:/app/data/raw
      - ./scripts:/app
    environment:
      - SPARK_MODE=client

  simulate:
    networks:
      - batch-energy-monitoring
    build:
      context: .
      dockerfile: simulate/Dockerfile
    container_name: simulate
    volumes:
      - ./simulate:/app
      - data_raw:/app/data/raw
      - data_clean:/app/data/clean
